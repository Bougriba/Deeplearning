{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl3XqrjsrgTkc8HUHi6Ndh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bougriba/Deeplearning/blob/main/Predict_whether_the_customer_will_stay_or_leave_the_bank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "TeWuJVCGoSYy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E64knI_UeVdn",
        "outputId": "b0e1c4d0-fd8a-46bc-ded0-9020fa398bca"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.13.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "khaSdxsGop46"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_gender_values = dataset['Gender'].unique()\n",
        "unique_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utawFJ-Eq1nQ",
        "outputId": "4d6e9f0d-3505-405a-ee3d-eb18c608136f"
      },
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Female', 'Male'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_Geographe_values = dataset['Geography'].unique()\n",
        "unique_Geographe_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1mnFo_crUl5",
        "outputId": "8ab8a42e-2fec-41fd-dcdc-61ddea69d9a3"
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['France', 'Spain', 'Germany'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4VZWHsxo_md",
        "outputId": "008ea85a-da0a-42e1-d08f-481743e4d8cb"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of       RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "0             1    15634602   Hargrave          619    France  Female   42   \n",
              "1             2    15647311       Hill          608     Spain  Female   41   \n",
              "2             3    15619304       Onio          502    France  Female   42   \n",
              "3             4    15701354       Boni          699    France  Female   39   \n",
              "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
              "...         ...         ...        ...          ...       ...     ...  ...   \n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          2       0.00              1          1               1   \n",
              "1          1   83807.86              1          0               1   \n",
              "2          8  159660.80              3          1               0   \n",
              "3          1       0.00              2          0               0   \n",
              "4          2  125510.82              1          1               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           101348.88       1  \n",
              "1           112542.58       0  \n",
              "2           113931.57       1  \n",
              "3            93826.63       0  \n",
              "4            79084.10       0  \n",
              "...               ...     ...  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  \n",
              "\n",
              "[10000 rows x 14 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:,3:13].values\n",
        "y = dataset.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "HGkTZS_K7kH9"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_h2asv--Owm",
        "outputId": "d5131a55-e3c2-4447-87e3-e333dfd5ab35"
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n"
      ],
      "metadata": {
        "id": "imc6R91StJkQ"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:,4] = le.fit_transform(X[:,4])"
      ],
      "metadata": {
        "id": "j1cLEeDsfBT3"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = []\n",
        "for i in X[0]:\n",
        "  values.append(i)\n",
        "values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20uQ6br6iTT",
        "outputId": "7e248d88-3bb6-4fd3-9d1b-ea9a241de0e4"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.0, 0.0, 619, 0, 42, 2, 0.0, 1, 1, 1, 101348.88]"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "LRXqKgRNa32p"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWKaMJNodadF",
        "outputId": "f4a52fb0-209e-4e11-8398-93e6be4312cc"
      },
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0, 0.0, 1.0, 667, 0, 34, 5, 0.0, 2, 1, 0, 163830.64],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:,3:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4i-yOdXcF-I",
        "outputId": "64bbb8e9-f77b-4d3d-88fe-74dfecec0f86"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[667]\n",
            " [427]\n",
            " [535]\n",
            " ...\n",
            " [738]\n",
            " [590]\n",
            " [623]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:,3:4].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgQ3k6bocLCI",
        "outputId": "7ee218d1-2fc6-49b8-9d3e-65d8a23e4a54"
      },
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_array=X_train[:,3:4].shape[0]"
      ],
      "metadata": {
        "id": "tKxyNdB5ctW7"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_CreditScore = StandardScaler()\n",
        "sc_EstimatedSalary = StandardScaler()\n",
        "sc_Balance = StandardScaler()\n",
        "X_train[:,3:4] = sc_CreditScore.fit_transform(X_train[:,3:4])\n",
        "X_test[:,3:4] = sc_CreditScore.fit_transform(X_test[:,3:4])\n",
        "X_train[:,11:12] = sc_EstimatedSalary.fit_transform(X_train[:,11:12])\n",
        "X_test[:,11:12] = sc_EstimatedSalary.fit_transform(X_test[:,11:12])\n",
        "X_train[:,4:5] = sc_Balance.fit_transform(X_train[:,4:5])\n",
        "X_test[:,4:5] = sc_Balance.fit_transform(X_test[:,4:5])\n"
      ],
      "metadata": {
        "id": "gTpSzlsBs_Gq"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maWZEVVGb2lf",
        "outputId": "6fdef5ae-a1c1-4c0a-d201-1027c7abb61e"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0, 0.0, 1.0, 0.16958176236487524, -1.0916871447066732, 34, 5,\n",
              "       0.0, 2, 1, 0, 1.1064316603959772], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "roEesTHOmnk_"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.int32)"
      ],
      "metadata": {
        "id": "6g2j_LkfoClC"
      },
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential(\n",
        "    \t\t\t\t[\n",
        "\n",
        "        \t\t\t\tDense(6, activation='relu', name = 'layer1'),\n",
        "                Dense(6,activation='relu' , name='layer2'),\n",
        "        \t\t\t\tDense(1, activation='sigmoid', name = 'layer3')\n",
        "     \t\t\t\t]\n",
        "\t\t\t)\n",
        "model.compile(\n",
        "    \t\t\tloss = tf.keras.losses.BinaryCrossentropy(),\n",
        "   \t\t \toptimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "        metrics=['accuracy'],\n",
        "\t\t\t)\n",
        "\n",
        "model.fit(\n",
        "    \t\tX_train,y_train,\n",
        "    \t\tepochs=100,\n",
        "\t\t\t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w71JUk8mdPUM",
        "outputId": "6e1bebd9-bab3-4730-b8e5-9839fa259183"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 234.3689 - accuracy: 0.7190\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 112.1052 - accuracy: 0.7141\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 63.9528 - accuracy: 0.7181\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 24.0011 - accuracy: 0.7286\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4986 - accuracy: 0.7960\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7960\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7960\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7960\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7960\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7960\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7960\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7960\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7954\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7990\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7989\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.8002\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8006\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8016\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8004\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.8009\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8019\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.8031\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8030\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8021\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.8015\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8027\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.8023\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8016\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.8024\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.8015\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4628 - accuracy: 0.8001\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.8014\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4627 - accuracy: 0.8021\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8010\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8023\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7999\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.8023\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8015\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.8029\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8019\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8033\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.8024\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.8049\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8027\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8041\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8046\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8066\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8059\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8045\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8035\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8041\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8060\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.8045\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8060\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4501 - accuracy: 0.8077\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4509 - accuracy: 0.8060\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.8070\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4506 - accuracy: 0.8070\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8066\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8094\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8065\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8086\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4507 - accuracy: 0.8064\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8077\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.8086\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8096\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8092\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8099\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8110\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8081\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8081\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8083\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8085\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8101\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8090\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8096\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8091\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8090\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4462 - accuracy: 0.8091\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8081\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4464 - accuracy: 0.8102\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8106\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8102\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.8105\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8099\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8091\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.8092\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8108\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4442 - accuracy: 0.8096\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8099\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8095\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8100\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.8105\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8081\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8100\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8100\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8108\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8119\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8119\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78a461f6dd80>"
            ]
          },
          "metadata": {},
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CreditScore_Array = [[600]]\n",
        "EstimatedSalary_Array=[[50000]]\n",
        "Balance_Array=[[1222148]]\n",
        "CreditScore = sc_CreditScore.transform(CreditScore_Array)\n",
        "EstimatedSalary = sc_EstimatedSalary.transform(EstimatedSalary_Array)\n",
        "Balance = sc_Balance.transform(Balance_Array)"
      ],
      "metadata": {
        "id": "4hiMIoYHs4r3"
      },
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([[1,0,0,600,1,40,30,60000,2,1,1,50000]]) > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66trIoDgs7dg",
        "outputId": "92f3acea-8f7d-4b3d-ffa2-fb792fc9462d"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "[[ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.astype(np.float32)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate ( ( y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1) ),1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYGLXVN5wEdd",
        "outputId": "d8c2acc8-ece6-4f37-81ac-0df86a947e26"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.metrics import confusion_matrix , accuracy_score"
      ],
      "metadata": {
        "id": "hZJlcQCcxbsm"
      },
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " confusion_matrix(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1dMXDxhxq_2",
        "outputId": "adc6f282-b975-4fd7-a770-056f34602f19"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1576,   19],\n",
              "       [ 372,   33]])"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQdV5vMWxtw_",
        "outputId": "d1456719-d171-4f69-bda1-ddd7a27930a7"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8045"
            ]
          },
          "metadata": {},
          "execution_count": 435
        }
      ]
    }
  ]
}